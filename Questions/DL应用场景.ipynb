{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考文献\n",
    "\n",
    "https://www.zhihu.com/question/26726794/answer/1526236102?utm_source=wechat_session&utm_medium=social&utm_oi=583257441727287296&utm_content=group2_Answer&utm_campaign=shareopn\n",
    "\n",
    "https://zhuanlan.zhihu.com/p/25327755"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|算法|核心思路|优点|缺点|适用场景|\n",
    "|----|----|----|----|----|\n",
    "|线性回归||简单，上手快，对线性可分的数据有效，正则和cross-validation 可以避免过拟合|对outlier敏感，很容易过拟合或者underfitting(不知道中文翻译的什么). 无法处理非线性数据| -|\n",
    "|逻辑回归|为函数找到最合适的参数，使得函数的值和样本的值最接近。拟合的是一个概率学中的函数，f(x)的值这时候就反映了样本属于这个类的概率|简单，上手快，数据做不做预处理都无所谓，输出数据自动落入（0，1）区间，对输入数据的微小波动不敏感，可以通过数值分析方法进行模型优化|非线性数据表现不好，对于特征highly correlated的表现不好， 特征必须有明确指向性|很多分类算法的基础组件输出值自然地落在0到1之间，有概率意义。本质上是一个线性的分类器，所以处理不好特征之间相关的情况。效果一般，但模型清晰，背后的概率学经得住推敲。拟合出来的参数代表了每一个特征(feature)对结果的影响。是一个理解数据的好工具。|\n",
    "|SVM|找到不同类别之间的分界面，使得两类样本尽量落在面的两边，而且离分界面尽量远。利用核函数(kernel function)，可以把平面投射(mapping)成曲面，大大提高SVM的适用范围|线性非线性数据都可以处理，高维数据表现不错，当类型明确可分的时候是最优选择，outliers影响很小|慢， 当类型互相重叠时候表现不太好，kernel选择很重要，参数选择也很关键|尽量保持与样本间距离的性质导致它抗攻击的能力更强。和随机森林一样，这也是一个拿到数据就可以先尝试一下的算法。|\n",
    "|NN|利用训练样本(training sample)来逐渐地完善参数。如果输入输出是直接连接的就是LR。通过大量中间层的引入，能够捕捉很多输入特征之间的关系。卷积神经网络有很经典的不同层的可视化展示(visulization)|整体表现良好， 输入数据的波动影响小|慢，隐藏层选择很重要|数据量庞大，参数之间存在内在联系的时候。|\n",
    "|Naive Bayes|根据条件概率计算待判断点的类型|快，无需训练时间，较少的训练数据表现相对更好。irrelevant features 影响非常小，高维数据表现好.相对容易理解|不适合做预测， 输入数据必须代表整体分布不然会导致结果不好|需要一个比较容易解释，而且不同维度之间相关性较小的模型的时候。可以高效处理高维数据，虽然结果可能不尽如人意。至今依然被垃圾邮件过滤器使用|\n",
    "|决策树|总是在沿着特征做切分。随着层层递进，这个划分会越来越细.当我们预测一个孩子的身高的时候，决策树的第一层可能是这个孩子的性别。男生走左边的树进行进一步预测，女生则走右边的树。这就说明性别对身高有很强的影响|不需要预处理数据，可以处理部分数据丢失的情况，可以可视化，容易理解|容易过拟合，对outlier非常敏感，输入数据的微小波动会引起输出的大幅变化，不平衡/高维数据训练时间长|能够生成清晰的基于特征(feature)选择不同预测结果的树状结构，更好的理解数据。决策树最终在底层判断是基于单个条件的，攻击者只需要改变很少的特征就可以逃过监测。常见于垃圾邮件躲避检测中。受限于它的简单性，经常作为更有用的算法的基石。|\n",
    "|随机森林|随机选取不同的特征(feature)和训练样本(training sample)，生成大量的决策树，然后综合这些决策树的结果来进行最终的分类|人多力量大，可以降低综合误差（bias & variance），可以处理高维数据，不会出现过拟合.比决策树效果更好，改善容易被攻击的特点。|具体过程无法可视化，特征选择比较关键|数据维度相对低（几十维），同时对准确性有较高要求时。因为不需要很多参数调整就可以达到不错的效果，基本上不知道用什么方法的时候都可以先试一下随机森林。|\n",
    "|KNN|对于待判断的点，找到离它最近的几个数据点，根据它们的类型决定待判断点的类型.特点是完全跟着数据走，没有数学模型可言|简单好上手，对输入数据无要求，参数少，只有一个K|大量数据处理慢，数据量大+特征多的时候表现不好，imbalanced数据表现不好，无法处理数据丢失|需要一个特别容易解释的模型的时候。比如需要向用户解释原因的推荐算法。|\n",
    "|K-mean||可处理大量数据，保证收敛，对新数据适应良好|人工选择K， 初始数据完全影响整个模型的结果，高维数据速度慢，对outliers敏感|（空）|\n",
    "|Boosting|从一个最基础的分类器开始，每次寻找一个最能改善当前误差的分类器。用加权取和(weighted sum)的方式组合所有弱分类器|自带特征选择（feature selection），只使用在训练集中发现有效的特征(feature)。降低了分类时需要计算的特征数量，在一定程度上解决了高维数据难以理解的问题。|（空）|效果不逊于随机森林，自带特征选择（feature selection）所以对新手很友好，是一个“不知道用什么就试一下它吧”的算法。|\n",
    "|Bagging|随机地抽取训练集（training set），以之为基础训练多个弱分类器。通过取平均，或者投票(voting)的方式决定最终的分类结果。因为随机选取训练集，可以一定程度上避免过渡拟合(overfit)。|（空）|（空）|效果和参数的选择关系比较大，用默认参数往往没有很好的效果。虽然调对参数结果会比决策树和LR好，但是模型也变得复杂了，没事有特别的原因就别用它了|\n",
    "|stacking|在多个分类器的结果上，再套一个新的分类器。新的分类器就基于弱分类器的分析结果，加上训练标签(training label)进行训练。一般这最后一层用的是LR。|()|()|调参厉害的用。对于一般商用，它所带来的提升就很难值回额外的复杂度了。\n",
    "|HMM|通过上一个（或几个）状态预测下一个状态。状态本身我们是看不到的，我们只能根据状态生成的结果序列来学习可能的状态。|（）|（）|用于序列的预测，可以用来生成序列\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型选择考虑\n",
    "\n",
    "- 训练数据数据量是大还是小，数据是high bias 还是 high variance。数据小，或者数据high bias/ low variance 可以选择linear、 logistics regression, Naïve Bayes, 或者SVM无kernel。数据量大或low bias / high variance 可选择KNN, SVM 高斯kernel, 决策树。\n",
    "- 数据的结构考虑数据是线性还是非线性，相关还是不相关，根据上面的模型优缺点进行选择\n",
    "- 训练时间是想一杯茶喝一天等结果还是想嗖的一下就出结果，可以根据模型本身的速度选择。\n",
    "- 数据特征特征多还是少，特征是有明确指向性还是没有，特征之间有无重叠，都可以根据具体要求选择合适的模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
