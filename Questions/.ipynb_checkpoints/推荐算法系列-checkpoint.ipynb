{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考文献\n",
    "\n",
    "- Deep Learning for Matching in Search and Recommendation\n",
    "- https://zhuanlan.zhihu.com/p/101136699 推荐系统中的深度匹配模型\n",
    "- https://zhuanlan.zhihu.com/p/267263561  推荐系统总结之深度召回模型（上）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![推荐和搜索的本质，都是match的过程](https://pic3.zhimg.com/80/v2-18e28b76d97f4421ca943d38270e801e_720w.jpg)\n",
    "\n",
    "推荐系统和搜索应该是机器学习乃至深度学习在工业界落地应用最多也最容易变现的场景。而无论是搜索还是推荐，本质其实都是匹配，搜索的本质是给定query，匹配doc；推荐的本质是给定user，推荐item。本文主要讲推荐系统里的匹配问题，包括传统匹配模型和深度学习模型。\n",
    "\n",
    "匹配（matching）是衡量用户对物品的兴趣的过程，也是推荐召回中的工作内容。机器学习中是以learning to match的方式根据输入表示和标记数据学习一个匹配函数。而深度学习在其发展过程中以强大的表示学习和泛化能力加上算力提升、数据规模暴涨都使得深度模型在推荐召回中大放异彩。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 推荐系统概述\n",
    "\n",
    "## 0.1 推荐系统的本质\n",
    "\n",
    "定义：系统根据**用户的属性**（如性别、年龄、学历、地域、职业），用户在系统里**过去的行为**（例如浏览、点击、搜索、购买、收藏等），以及**当前上下文环境**（如网络、手机设备、时间等），从而给用户**推荐用户可能感兴趣的物品**（如电商的商品、feeds推荐的新闻、应用商店推荐的app等），从这个过程来看，推荐系统就是一个**给user匹配(match)感兴趣的item**的过程。\n",
    "\n",
    "## 0.2 推荐和搜索的比较\n",
    "\n",
    "都是一个match过程，图1.1展示的是一个搜索引擎的架构，需要match的是query和相关的doc；图1.2展示的是一个推荐系统的架构，需要match的是user(可能会带有主动意图的query)和相关的item。\n",
    "\n",
    "![图1搜素引擎架构](https://pic1.zhimg.com/80/v2-0be4057ee616ff2acd10c92c82336694_720w.jpg)\n",
    "\n",
    "![图2推荐系统架构](https://pic2.zhimg.com/80/v2-4f04a7013c8af1a71e285a994599b201_720w.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目录\n",
    "\n",
    "\n",
    "- [1 feature-based的深度模型](#1-feature-based的深度模型)\n",
    "    - [1.1 FM](#11-FM)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 无序行为的表示学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 FM\n",
    "\n",
    "![图1.1 FM模型的稀疏one-hot特征输入](https://pic1.zhimg.com/80/v2-5baaefa316db3345788b0256a4561134_720w.jpg)\n",
    "\n",
    "图1.1 FM模型的稀疏one-hot特征输入\n",
    "\n",
    "![图1.2 FM模型的数学表达](https://pic3.zhimg.com/80/v2-04cca7447d2205adb3edb26a7e1b980a_720w.jpg)\n",
    "\n",
    "图1.2 FM模型的数学表达\n",
    "\n",
    "对于每个输入特征，模型都需要学习一个低维的隐向量表示$v$，也就是NN中的embedding层。FM由两部分组成：蓝色的是LR线性模型，红色的是二阶特征组合——两两特征组合，但不和自己组合，向量之间的交叉用向量内积表示。\n",
    "\n",
    "```python\n",
    "feats = features['feats']  # [batch_size*feat_num, feat_val_num]\n",
    "emb = self.emb_module(feats)  # (bs*feature_num, feat_val_num, emb_dim) feat_val_num=1\n",
    "emb = tf.reshape(emb, [-1, self.total_feat_num, self.emb_dim])  # (bs, feat_num, emb_dim) feat_val_num=1 \n",
    "\n",
    "# -----LR-----\n",
    "linear_emb = self.linear_emb_module(feats)  # (bs*feature_num, feat_val_num, emb_size) feat_val_num=1,emb_size=1\n",
    "linear_emb = tf.reshape(linear_emb, [-1, self.total_feat_num*1]) # （bs,feat_num）\n",
    "linear_out = tf.reduce_sum(linear_emb, 1, keep_dims=True)  # [bs, 1]\n",
    "\n",
    "# -----二阶-----\n",
    "# The shape of embedding is [bs, feature_num, emb_dim]\n",
    "summed_features_emb_square = tf.square(tf.reduce_sum(emb,1))  # [bs,feature_num,emb_dim] -> [bs, emb_dim]\n",
    "squared_sum_features_emb = tf.reduce_sum(tf.square(emb),1)  # [bs,feature_num,emb_dim] -> [bs, emb_dim]\n",
    "FM2 = 0.5 * tf.subtract(summed_features_emb_square, squared_sum_features_emb)  # [bs, emb_dim] \n",
    "# [bs, emb_dim]的FM结果与特征两两逐元素相乘加和再tf.reduce_sum(pairwise_interaction, 1)消除第二维度（feat_num*(feat_num-1)/2）得到的[bs, emb_dim]结果一致\n",
    "\n",
    "FM = tf.reduce_sum(FM2, 1) + linear_out # [bs,] 按照FM计算公式有此步骤\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Wide&Deep\n",
    "\n",
    "-  [2016]\"Wide & Deep Learning for Recommender Systems\": https://arxiv.org/abs/1606.07792 [2] [official] https://github.com/tensorflow/models/tree/master/official/wide_deep \n",
    "\n",
    "\n",
    "![wd模型图](https://github.com/hsux/Distributed-training/raw/master/images/wd_imgs/wd.jpg)\n",
    "\n",
    "（1） 记忆性：wide部分长处在于学习样本中的**高频**部分。\n",
    "- 优点是模型的**记忆性好**，对于样本中出现过的**高频低阶特征能够用少量参数学习**；\n",
    "- 缺点是模型的**泛化能力差**，例如对于没有见过的ID类特征，模型学习能力较差。\n",
    "\n",
    "（2） 泛化性：deep部分长处在于学习样本中的**长尾**部分。\n",
    "- 优点是**泛化能力强**，对于**少量出现过的样本甚至没有出现过的样本都能做出预测（非零的embedding向量）**，容易带来惊喜。\n",
    "- 缺点是模型**对于低阶特征的学习需要用较多参数才能等同wide部分效果**，而且泛化能力强某种程度上也**可能导致过拟合出现bad case**。尤其对于冷启动的一些item，也有可能给用户带来惊吓。\n",
    "\n",
    "![模型框架2](https://pic1.zhimg.com/80/v2-0bb7650022db2d677b029bb39537ed60_720w.jpg)\n",
    "\n",
    "虽然模型的deep部分拟合和泛化能力很强，但绝对不意味着把特征交叉都交给MLP就够了。实际证明，对于重要的一些人工经验的特征，对于提升整体效果还是非常重要的，如上图所示。这个人工特征的所谓缺点，也是后续各种模型结构想对其进行“自动化”的优化点。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Deep Crossing\n",
    "\n",
    "- 2016 微软\n",
    "\n",
    "wide&deep的MLP部分是全连接网络，每层的输入是前一层的输出，受限于模型结构，**越往后的层越难学习到原始输入的表达，一般深度不会太深**，超过5层的网络在工业界已经算很少见了。为了解决这个问题，deep crossing网络引入了resnet残差网络的概念，**通过`short-cut`，在MLP的深层网络，也能接收来自第一层的输入，这样可以使得模型的深度达到10层之多**。\n",
    "\n",
    "![deep crossing模型框架](https://pic4.zhimg.com/80/v2-cc6b972eb9e73816a454d154413a4a73_720w.jpg)\n",
    "\n",
    "上述提到的wide&deep以及deep crossing框架更像是在模型结构做的改进，一个引入了wide&deep，一个引入了resnet，**特征层面并没有做太多改造**，如何体现feature-base呢？sigIR2017就有一篇文章做了个实验，对wide&deep以及Deep&Cross实验*按照embedding是否做初始化分别做了实验*。实验发现，如果embedding是随机初始化的，两个深度模型连基础的FM模型都打不过；哪怕经过FM初始化了embedding，wide&deep模型效果也仅仅略好于FM模型，而deep crossing模型依然比不过FM模型，实验结果如下图所示：\n",
    "\n",
    "![不同初始化对模型影响](https://pic3.zhimg.com/80/v2-07bbaf8ac3eafe8a87ba09b50f39db26_720w.jpg)\n",
    "\n",
    "全连接网络表面上看对所有节点都进行了连接，理论上应该学习到了各个节点的交叉特征，但是从结果上来看，**MLP对这些特征交叉的学习能力确实非常差的**。纠其原因，还是在模型结构的设计上。\n",
    "\n",
    "![wide&deep模型和deep crossing模型](https://pic1.zhimg.com/80/v2-a76f166f96a59270b7108b352d48e974_720w.jpg)\n",
    "\n",
    "上图中两种模型，embedding到MLP之间都是做emb-concat，concat的结果表达的交叉信息有限，仅靠MLP想完全捕捉有效交叉信息是困难的，于是在embedding与MLP之间利用更多的数学先验范式做特征交叉是一个改进的方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 PNN\n",
    "\n",
    "- 在embedding与MLP之间引入product layer显式地学习每个field的embedding向量间的两两交叉。\n",
    "\n",
    "![PNN模型框架](https://pic2.zhimg.com/80/v2-6a31278d8d55c8516a891c088c287a79_720w.jpg)\n",
    "\n",
    "上图中，product layer左边z维embedding层的线性部分，右边p为embedding层的特征交叉部分。思想来源于推荐系统中特征间的交叉关系更多是一种“且”的关系而非“加”的关系。例如，性别为男且喜欢游戏的人群，比起性别男和喜欢游戏的人群，前者的组合比后者更能体现特征交叉的意义。\n",
    "\n",
    "根据product的方式不同，可以分为inner product（IPNN）和outer product(OPNN)，如下图所示：\n",
    "\n",
    "![PNN模型的两种不同交叉方式](https://pic3.zhimg.com/80/v2-695f940fca822ff863f6393631fed7ea_720w.jpg)\n",
    "\n",
    "其中，IPNN模型每个特征是个inner product, f个field两两交叉，得到的新的特征组合有$f*(f-1)/2$个；outer product是两个向量的乘积，得到的新的特征组合有$f*(f-1)/2*k*k$个。\n",
    "\n",
    "```python\n",
    "\n",
    "feats = features['feats']  # [batch_size*feat_num, feat_vals]\n",
    "pairwise_emb = self.pairwise_emb_module(feats)  # dense:(bs*feature_num, feat_val_num, emb_dim) \n",
    "pairwise_emb = tf.reshape(pairwise_emb, [-1, self.total_feat_num, self.emb_dim])  # (bs, feat_num, emb_dim)\n",
    "        \n",
    "# ----z part. [bs, self.total_feat_num, self.emb_dim] -> [bs, self.total_feat_num*self.emb_dim]\n",
    "z_part = tf.reshape(pairwise_emb, [-1, self.total_feat_num*self.emb_dim]) \n",
    "\n",
    "# IPNN-------------------------\n",
    "class PairwiseInteraction(BaseModule):\n",
    "    '特征emb两两元素乘'\n",
    "    def __init__(self, name, feat_num):\n",
    "        super(PairwiseInteraction, self).__init__(name)\n",
    "        self.feat_num = feat_num\n",
    "        \n",
    "    @tf.Module.with_name_scope\n",
    "    def __call__(self, embeddings)\n",
    "        ''' embeddings: [bs, feat_num, emb_dim]\n",
    "            return [bs, feat_num*(feat_num-1)/2, emb_dim]\n",
    "        '''\n",
    "        elementwise_list = []\n",
    "        for i in range(self.feat_num):\n",
    "            for j in range(i+1, self.feat_num):\n",
    "                elementwise_list.append(tf.multiply(embeddings[:,i,:],embeddings[:,j,:]))  # [(bs,emb_dim),....,] 共feat_num*(feat_num-1)/2个\n",
    "                \n",
    "        pairwise_interaction = tf.stack(elementwise_list)  # [feat_num * (feat_num - 1) / 2, bs, emb_dim]\n",
    "        pairwise_interaction = tf.transpose(pairwise_interaction, perm=[1,0,2])  # [bs, feat_num * (feat_num - 1) / 2, emb_dim]\n",
    "        return pairwise_interaction  # 交互项矩阵\n",
    "    \n",
    "self.p_part_module = PairwiseInteraction(\n",
    "    name='p_part_module',\n",
    "    feat_num=self.total_feat_num,\n",
    ")\n",
    "p_part = self.p_part_module(pairwise_emb)\n",
    "p_part = tf.reshape(tf.reduce_sum(p_part, axis=-1), [-1, self.total_pairs])\n",
    "\n",
    "# OPNN--------------------\n",
    "if outer_mode == 'mat':\n",
    "    self.outer_kernel = OuterKernel(\n",
    "        name='outer_kernel',\n",
    "        shape=[self.emb_dim,self.total_pairs,self.emb_dim]\n",
    "    )\n",
    "elif outer_mode == 'vec':\n",
    "    self.outer_kernel = OuterKernel(\n",
    "        name='outer_kernel',\n",
    "        shape=[self.total_pairs,self.emb_dim]\n",
    "    )\n",
    "else: # outer_mode == 'num'\n",
    "    self.outer_kernel = OuterKernel(\n",
    "        name='outer_kernel',\n",
    "        shape=[self.total_pairs,1]\n",
    "    ) \n",
    "\n",
    "if self.product_mode == 'outer':\n",
    "    p, q = self.pairs_emd_module(pairwise_emb)  # [bs,total_pairs,emb_dim]\n",
    "    if self.outer_mode == 'mat':\n",
    "        # p与outer_kernel元素积，结果再与q元素积\n",
    "        p = tf.expand_dims(p,1)  # [bs, total_pairs, emb_dim] -> [bs,1,total_pairs,emb_dim]\n",
    "        p_part = tf.reduce_sum(  # [bs, total_pairs]\n",
    "                 tf.multiply(  # [bs, total_pairs, emb_dim]\n",
    "                     tf.transpose(  # [bs, total_pairs, emb_dim]\n",
    "                         tf.reduce_sum(  # [bs, emb_dim, total_pairs]\n",
    "                             tf.multiply(p, self.outer_kernel),  # [bs,emb_dim,total_pairs,emb_dim]\n",
    "                             axis=-1\n",
    "                         ),  # reduce_sum\n",
    "                         perm=[0,2,1]\n",
    "                     ),  # transpose\n",
    "                     q\n",
    "                 ),  # multiply\n",
    "                 axis=-1\n",
    "             )  # reduce_sum\n",
    "    else:\n",
    "        # p,q,kernel元素积\n",
    "        kernel = tf.expand_dims(self.outer_kernel,0)  # vec:[1,total_pairs,emb_dim],num:[1,total_pairs,1] \n",
    "        p_part = tf.reduce_sum(p*q*kernel, axis=-1)  # [bs,total_pairs]\n",
    "# ----deep net\n",
    "# [bs, self.total_feat_num*self.emb_dim] concat [bs, feat_num*(feat_num-1)/2] -> [bs, self.total_emb_dim+feat_num*(feat_num-1)/2]\n",
    "deep_input = tf.concat([z_part, p_part], axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 DeepFM\n",
    "\n",
    "- [IJCAI 2017]\"DeepFM: A Factorization-Machine based Neural Network for CTR Prediction\": https://arxiv.org/abs/1703.04247v1\n",
    "\n",
    "\n",
    "wide&deep框架虽然强大，但是LR模型需要人工进行特征工程，华为诺亚方舟团队结合FM相比LR的特征交叉，在17年提出了DeepFM，将wide&deep中的LR部分替换为FM，避免人工特征工程，如下图所示：\n",
    "\n",
    "![deepfm框架](https://pic3.zhimg.com/80/v2-aef79867ec40a8327366333d5764ede2_720w.jpg)\n",
    "\n",
    "- 更强的低阶特征表达：wide部分取代WDL的LR，与wide&deep模型以及deep crossing模型相比更能捕捉低阶特征信息\n",
    "\n",
    "- embedding层共享：wide&deep部分的embedding层需要针对deep部分单独设计；而在deepFM中，FM和DEEP部分共享embedding层，FM训练得到的参数既作为wide部分的输出，也作为DNN部分的输入。\n",
    "\n",
    "- end-end训练：embedding和网络权重联合训练，无需预训练和单独训练\n",
    "\n",
    "- 缺点：FM部分输出emb_size可能比dnn输出部分小太多\n",
    "\n",
    "```python\n",
    "feats = features['feats']  # [batch_size*feat_num, feat_vals]\n",
    "linear_emb = self.linear_emb_module(feats)  # dense:(bs*feature_num, feat_val_num, 1) \n",
    "linear_emb = tf.reshape(linear_emb, [-1, self.total_feat_num*1])\n",
    "second_emb = self.pairwise_emb_module(feats)  # dense:(bs*feature_num, feat_val_num, emb_dim) \n",
    "second_emb = tf.reshape(second_emb, [-1, self.total_feat_num, self.emb_dim])  # (bs, feat_num * feat_val_num * emb_dim) feat_val_num=1 in dense\n",
    "\n",
    "# ----Linear Module\n",
    "# [bs, feat_num] -> [bs, 1]\n",
    "linear_out = tf.reduce_sum(linear_emb, 1, keep_dims=True) \n",
    "\n",
    "# ----FM Module\n",
    "# [bs, feat_num, emb_dim] -> [bs, emb_dim]\n",
    "# The shape of embedding is [bs, feature_num, emb_dim]\n",
    "summed_features_emb_square = tf.square(tf.reduce_sum(second_emb,1))  # [bs,feature_num,emb_dim] -> [bs, emb_dim]\n",
    "squared_sum_features_emb = tf.reduce_sum(tf.square(second_emb),1)  # [bs,feature_num,emb_dim] -> [bs, emb_dim]\n",
    "FM = 0.5 * tf.subtract(summed_features_emb_square, squared_sum_features_emb)  # [bs, emb_dim] \n",
    "\n",
    "# ----Deep Module\n",
    "# [bs, total_emb_dim] -> [bs, dnn_layers[-1]]\n",
    "dnn_out = self.dnn_module(tf.reshape(second_emb,shape=[-1, self.total_emb_dim]), is_train)\n",
    "\n",
    "# ----second order out\n",
    "# [bs, emb_dim + dnn_layers[-1]] -> [bs, 1]\n",
    "second_input = tf.concat([FM_out, dnn_out], axis=1)\n",
    "second_order_out = self.second_order_out(second_input, is_train)  #dense * 1\n",
    "\n",
    "# ----DeepFM output\n",
    "global_bias = tf.Variable(name='global_bias', initial_value=tf.zeros_initializer()(shape=[1]), dtype=tf.float32)\n",
    "global_bias = global_bias * tf.ones_like(global_bias, dtype=tf.float32)  # [bs, 1]  否则报错\n",
    "model_out = tf.add_n([global_bias, linear_out, second_order_out])  # [bs, 1]\n",
    "model_out = self.out_act(model_out)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 NFM(Neural Factorization Machines)\n",
    "\n",
    "- [SIGIR 2017]\"Neural Factorization Machines for Sparse Predictive Analytics\": https://arxiv.org/abs/1708.05027\n",
    "- https://github.com/hexiangnan/neural_factorization_machine\n",
    "\n",
    "deepFM在embedding层后把FM部分直接**concat**起来（f\\*k维，f个field，每个filed是k维向量）作为DNN的输入。Neural Factorization Machines，简称NFM，提出了一种更加简单粗暴的方法，在embedding层后，做了一个叫Bi-interaction的操作，让**各个field做element-wise后sum**起来去做特征交叉，MLP的**输入规模直接压缩到k维**，和特征的原始维度ｎ和特征field维度f没有任何关系，如下图所示：\n",
    "\n",
    "![NFM模型框架](https://pic1.zhimg.com/80/v2-f38d5cee16581c7af469ba13af7f82a4_720w.jpg)\n",
    "\n",
    "图中只画出了其中的deep部分, wide部分在这里省略没有画出来。Bi-interaction所做的操作很简单：让**f个field两两element-wise相乘**后，得到f*(f-1)/2个维度为k的向量，然后直接**sum**起来，最后得到一个k维的向量。所以该层**没有任何参数需要学习，同时也降低了网络复杂度，能够加速网络的训练**；但同时这种方法也**可能带来较大的信息损失**。\n",
    "\n",
    "- 就是把DeepFM中的FM和dnn并联改成了FM和dnn串联\n",
    "\n",
    "```python\n",
    "feats = features['feats']  # [batch_size*feat_num, feat_val_num]\n",
    "linear_emb = self.linear_emb_module(feats)  # dense:(bs*feature_num, feat_val_num, 1) feat_val_num=1 in dense; sparse:(bs*feature_num, 1) because combiner\n",
    "linear_emb = tf.reshape(linear_emb, [-1, self.total_feat_num*1])\n",
    "emb = self.emb_module(feats)  # dense:(bs*feature_num, feat_val_num, emb_dim) feat_val_num=1 in dense; sparse:(bs*feature_num, emb_dize) because combiner\n",
    "emb = tf.reshape(emb, [-1, self.total_feat_num, self.emb_dim])  # (bs, feat_num, emb_dim) feat_val_num=1 in dense; \n",
    "\n",
    "# Model\n",
    "# 原文中此处是x_i为one-hot编码的0或1，样本Xone-hot向量的第i个特征，求加权和\n",
    "# 官方实现如下\n",
    "linear_out = tf.reduce_sum(linear_emb, 1, keep_dims=True)  # [bs, 1]\n",
    "\n",
    "# ---- Bi_Interaction\n",
    "# emb shape is [bs,feature_num,emb_dim]\n",
    "# The shape of embedding is [bs, feature_num, emb_dim]\n",
    "summed_features_emb_square = tf.square(tf.reduce_sum(second_emb,1))  # [bs,feature_num,emb_dim] -> [bs, emb_dim]\n",
    "squared_sum_features_emb = tf.reduce_sum(tf.square(second_emb),1)  # [bs,feature_num,emb_dim] -> [bs, emb_dim]\n",
    "bi_out = 0.5 * tf.subtract(summed_features_emb_square, squared_sum_features_emb)  # [bs, emb_dim] \n",
    "\n",
    "# -----Deep\n",
    "deep_out = self.deep_module(bi_out, is_train=is_train)  # [bs, deep_layer[-1]]\n",
    "deep_out = self.final_module(deep_out, is_train=is_train)  # [bs, 1]\n",
    "\n",
    "# NFM output\n",
    "global_bias = tf.Variable(name='global_bias', initial_value=tf.zeros_initializer(), shape=[1]), dtype=tf.float32)\n",
    "global_bias = global_bias * tf.ones_like(global_bias, dtype=tf.float32)  # [bs, 1]  否则报错\n",
    "model_out = tf.add_n([global_bias, linear_out, deep_out])  # [bs, 1] must equal rank\n",
    "model_out = self.out_act(model_out)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 AFM\n",
    "\n",
    "提到的各种网络结构中的FM在做特征交叉时，让不同特征的向量直接做交叉，基于的假设是**各个特征交叉对结果的贡献度是一样的**。这种假设往往不太合理，原因是**不同特征对最终结果的贡献程度一般是不一样的**。Attention Neural Factorization Machines，简称AFM模型，利用了近年来在图像、NLP、语音等领域大获成功的attention机制，在前面讲到的NFM基础上，引入了attention机制来解决这个问题，如下图所示。\n",
    "\n",
    "![AFM](https://pic1.zhimg.com/80/v2-eb07df13a0010c275bbf8ecba72edb2c_720w.jpg)\n",
    "\n",
    "AFM的embedding层后和NFM一样，先让f个field的特征做了element-wise product后，得到$f*(f-1)/2$个交叉向量。和NFM直接把这些交叉项sum起来不同，AFM引入了一个Attention Net，认为这些交叉特征项每个对结果的贡献是不同的，例如xi和xj的权重重要度，用aij来表示。从这个角度来看，其实AFM其实就是个**加权累加**的过程。Attention Net部分的权重aij不是直接学习，而是通过如下公式表示:\n",
    "\n",
    "![AFM公式](https://pic1.zhimg.com/80/v2-941f8604f6e7644f2648410be6da9094_720w.jpg)\n",
    "![](https://pic4.zhimg.com/80/v2-9bd6536205efe338fc4b1deb182d96c3_720w.png)\n",
    "\n",
    "其中t表示attention net中的隐层维度，k和前面的一样，为embedding层的维度emb_size。需要学习的参数只有3个，$W,b,h$，参数个数共有$t*k+2*t$个。得到aij权重后，对各个特征两两点积加权累加后，得到一个k维向量，引入一个简单的参数向量pT,维度为k进行学习，和wide部分一起得到最后的AFM输出。\n",
    "\n",
    "![AFM模型中attention的可视化解释](https://pic3.zhimg.com/80/v2-4b3a096d531539fa495495f2e7d2d7aa_720w.jpg)\n",
    "\n",
    "关于AFM还有个好处，通过attention-base pooling计算的score值aij体现的是特征vi和vj之间的权重，能够选择有用的二阶特征，如上图所示。\n",
    "\n",
    "```python\n",
    "\n",
    "feats = features['feats']  # [batch_size*feat_num, feat_val_num]\n",
    "linear_emb = self.linear_emb_module(feats)  # dense:(bs*feature_num, feat_val_num, 1)  feat_val_num=1\n",
    "linear_emb = tf.reshape(linear_emb, [-1, self.total_feat_num*1])\n",
    "pairwise_emb = self.pairwise_emb_module(feats)  # dense:(bs*feature_num, feat_val_num, emb_dim)  feat_val_num=1 \n",
    "pairwise_emb = tf.reshape(pairwise_emb, [-1, self.total_feat_num, self.emb_dim])  # (bs, feat_num * feat_val_num, emb_dim) feat_val_num=1 \n",
    "\n",
    "# ----Linear Module\n",
    "# 官方reduce_sum, [bs, self.total_feat_num] -> [bs, 1]\n",
    "linear_out = tf.reduce_sum(linear_emb, 1, keep_dims=True) \n",
    "\n",
    "# ----Pairwise Interaction Module\n",
    "# feat vec两两逐元素相乘 [bs, self.total_feat_num, emb_dim] -> [bs, feat_num * (feat_num - 1) / 2, emb_dim]\n",
    "elementwise_list = []\n",
    "for i in range(self.feat_num):\n",
    "    for j in range(i+1, self.feat_num):\n",
    "        elementwise_list.append(tf.multiply(pairwise_emb[:,i,:],v[:,j,:]))  # (bs,emb_dim)\n",
    "        \n",
    "pairwise_interaction = tf.stack(elementwise_list)  # [feat_num * (feat_num - 1) / 2, bs, emb_dim]\n",
    "pairwise_interaction_out = tf.transpose(pairwise_interaction, perm=[1,0,2])  # [bs, feat_num * (feat_num - 1) / 2, emb_dim]\n",
    "\n",
    "\n",
    "# ----Attention Module 公式()第三部分，官方没有h\n",
    "if self.use_att:\n",
    "    # relu(wx+b): [bs, feat_num * (feat_num - 1) / 2, emb_dim] -> [bs, feat_num * (feat_num - 1) / 2, att_layer[-1]]\n",
    "    attention_wx_plus_b = self.attention_nn_module(pairwise_interaction_out, is_train)  # MLP layer\n",
    "    # P*attention_wx_plus_b: [bs, feat_num * (feat_num - 1) / 2, att_layer[-1]] -> [bs, feat_num * (feat_num - 1) / 2, 1]\n",
    "    attention_p_mul = tf.reduce_sum(tf.multiply(self.attention_p, attention_wx_plus_b)), 2, keep_dims=True) # att_p is a rand var. \n",
    "    # 官方代码增加dropout\n",
    "    attention_score = tf.nn.dropout(tf.softmax(self.attention_p_mul), self.att_keep_prob)  # [bs, feat_num * (feat_num - 1) / 2, 1]\n",
    "\n",
    "# ----Attention-aware Pairwise Interaction Layer\n",
    "if self.use_att:\n",
    "    # 在FM计算reduce_sum之前对两两特征交叉的结果进行attention\n",
    "    # att_score * PI: [bs, feat_num * (feat_num - 1) / 2, 1] * [bs, feat_num * (feat_num - 1) / 2, emb_dim] -> [bs, emb_dim]\n",
    "    afm = tf.reduce_sum(tf.multiply(attention_score, pairwise_interaction_out), axis=1, name='afm')   # [bs, emb_dim]\n",
    "else:\n",
    "    # [bs, feat_num * (feat_num - 1) / 2, emb_dim] -> [bs, emb_dim]\n",
    "    afm = tf.reduce_sum(pairwise_interaction_out, axis=1, name='afm')   # [bs, emb_dim]\n",
    "    \n",
    "afm = tf.nn.dropout(afm, self.afm_keep_prob)  # 官方\n",
    "# second_order output, fc layer\n",
    "# w matmul afm: [bs, emb_dim] matmul [emb_dim, 1] -> [bs, 1]\n",
    "second_order_out = self.second_order_out(afm, is_train)\n",
    "\n",
    "# AFM output\n",
    "global_bias = tf.Variable(name='global_bias', initial_value=tf.zeros_initializer()(shape=[1]), dtype=tf.float32)\n",
    "global_bias = global_bias * tf.ones_like(global_bias, dtype=tf.float32)  # [bs, 1]  否则报错 \n",
    "model_out = tf.add_n([global_bias, linear_out, second_order_out], name='afm_out')  # [bs, 1]  must equal rank\n",
    "model_out = self.out_act(model_out)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 DCN\n",
    "\n",
    "前面提到的几种FM-based的方法都是做的**二阶特征交叉**，如PNN用`product`方式做二阶交叉，NFM和AFM也都采用了`Bi-interaction`的方式学习特征的二阶交叉。对于更高阶的特征交叉，只有让deep去学习了。为解决这个问题，google在2017年提出了Deep&Cross Network，简称DCN的模型，**可以任意组合特征，而且不增加网络参数**。下图为DCN的结构：\n",
    "\n",
    "![DCN模型](https://pic2.zhimg.com/80/v2-0f89c6100db6fde81b9568046103e509_720w.jpg)\n",
    "\n",
    "整个网络分4部分组成：\n",
    "\n",
    "### 1）Embedding and stacking layer\n",
    "\n",
    "之所以不把`embedding`和`stacking`分开来看，是因为很多时候，`embedding`和`stacking`过程是分不开的。前面讲到的各种 XX-based FM 网络结构，利用FM学到的$v$向量可以很好的作为`embedding`。而在很多实际的业务结构，可能已经有了提取到的`embedding`特征信息，例如图像的特征embedding，text的特征embedding，item的embedding等，还有其他连续值信息，例如年龄，收入水平等，这些embedding向量stack在一起后，一起作为后续网络结构的输入。当然，这部分也可以用前面讲到的FM来做embedding。为了和原始论文保持一致，这里我们假设$X_0$向量维度为$d$（上文的网络结构中为$k$，即emb_size），这一层的做法就是简答的把各种embedding向量concat起来。\n",
    "\n",
    "![公式](https://pic3.zhimg.com/80/v2-39276f565d2ba8600da6a8334fd82cea_720w.png)\n",
    "\n",
    "### 2）deep layer network\n",
    "\n",
    "在embedding and stacking layer之后，网络分成了两路，一路是传统的DNN结构。表示如下：\n",
    "\n",
    "$$h_{l+1}=f(W_lh_l+b_l)$$\n",
    "\n",
    "为简化理解，假设每一层网络的参数有$m$个，一共有$L_d$层，输入层由于和上一层连接，有$d*m$个参数（$d$为$X_0$向量维度），后续的$L_{d-1}$层，每层需要$m*(m+1)$个参数，所以一共需要学习的参数有 $d*m+m*(m+1)*(L_{d-1})$。最后的输出也是个$m$维向量\n",
    "\n",
    "### 3）cross layer network\n",
    "\n",
    "embedding and stacking layer输入后的另一路就是DCN的重点工作了。每一层$l+1$和前一层$l$的关系可以用如下关系表示:\n",
    "\n",
    "$$x_{l+1}=x_0x^T_lw_l+b_l+x_l=f(x_l,w_l,b_l)+x_l$$\n",
    "\n",
    "可以看到f是待拟合的函数，$x_l$即为上一层的网络输入。需要学习的参数为$w_l$和$b_l$，因为$x_l$维度为$d$，当前层网络输入$x_{l+1}$也为$d$维，待学习的参数$w_l$和$b_l$也都是$d$维向量。因此，每一层增加$2*d$的参数（$w$和$b$）需要学习，整体增加$2L_cd$个参数，$L_c$为cross net层数。网络结构如下:\n",
    "\n",
    "![cross net](https://pic3.zhimg.com/80/v2-a0098c8e0efa55c689b6ededffd94c82_720w.jpg)\n",
    "\n",
    "经过$L_c$层的`cross layer network`后，在该layer最后一层$L_c$层的输出为$d$维向量\n",
    "\n",
    "### 4）combination output layer\n",
    "\n",
    "经过`cross network`的输出$X_{L_1}$($d$维）和`deep network`之后的向量输出（$m$维）直接做`concat`，变为一个$d+m$的向量，最后套一个LR模型，需要学习参数为$1+d+m$。\n",
    "\n",
    "总结起来，DCN引入的cross network**理论上可以表达任意高阶组合，同时每一层保留低阶组合，参数的向量化也控制了模型的复杂度**。cross网络部分的交叉学习的是**特征向量中每一个element的交叉，本质上是`bit-wise`的**。\n",
    "\n",
    "```python\n",
    "# cross net\n",
    "input_units = x0.shape(1)  #[bs,feat_num * emb_size]\n",
    "prev = x0\n",
    "for i in range(cross_layer_num):\n",
    "    self.kernel = tf.Variable(\n",
    "               name='kernel',\n",
    "               initial_value=kernel_initializer(shape=[input_units, 1]),\n",
    "               dtype=tf.float32\n",
    "     )\n",
    "    self.bias = tf.Variable(\n",
    "              name='bias',\n",
    "              initial_value=bias_initializer(shape=[input_units]),\n",
    "              dtype=tf.float32\n",
    "     )\n",
    "    xb = tf.matmul(prev, self.kernel)  # matmul([bs, input_units], [input_units,1]) --> [bs, 1]\n",
    "    prev = x0 * xb + self.bias + prev  # elem_mul([bs, input_units], [bs, 1]) + [input_units,] + [bs, input_units] --> [bs, input_units]\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) cross net部分改进\n",
    "\n",
    "- DCN-M模型能够简单且有效地建模显式特征交叉，并通过混合低秩矩阵在模型效果和时延上实现了更好的权衡。DCN-M已成功应用于多个大型L2R系统，取得了显著的线下及线上收益。实验结果表明DCN-M的效果超过了现有SOTA方法。\n",
    "\n",
    "DCN中cross网络的参数是向量，DCN-M中换成了矩阵来提高表达能力、方便落地。DCN-M是指“DCN-matrix” ，原来的DCN在这里称为DCN-V（“DCN-vector”）。\n",
    "\n",
    "$$x_{l+1}=x_0 \\odot (W_lx_l + b_l)+x_l$$\n",
    "\n",
    "其中$x_l,x_{l+1},b_l \\in R^T, W_l \\in R^{d*d}$\n",
    "\n",
    "![dcn-m](../imgs/dcn_m_cross.jpg)\n",
    "\n",
    "```python\n",
    "if self.parameterization == 'vector':\n",
    "    xl_w = torch.tensordot(x_l, self.kernels[i], dims=([1], [0]))  # x' * w (bs, 1)\n",
    "    dot_ = torch.matmul(x_0, xl_w)  # x0 * (x' * w) (bs, input_units)\n",
    "    x_l = dot_ + self.bias[i]\n",
    "elif self.parameterization == 'matrix':\n",
    "    dot_ = torch.matmul(self.kernels[i], x_l)  # W * xi  (bs, in_features, 1)\n",
    "    dot_ = dot_ + self.bias[i]  # W * xi + b\n",
    "    dot_ = x_0 * dot_  # x0 · (W * xi + b)  Hadamard-product 逐元素乘积\n",
    "x_l = dot_ + x_l\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6） deep和cross的结合方式\n",
    "\n",
    "结合方式分为堆叠（串行）和并行两种：\n",
    "\n",
    "![stack_paraller](../imgs/dcn_m_stack_parallel.jpg)\n",
    "\n",
    "这两种结合方式下的DCN-M效果都优于基准算法。但这两种结构之间的优劣不能一概而论，与数据集有关。串行结构在criteo数据集上更好，而并行结构在Movielen-1M上效果更好。\n",
    "\n",
    "**DCN-M的损失函数为带L2正则的log loss**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) 低秩优化计算性能\n",
    "\n",
    "工业界模型往往受计算资源和响应时间限制，需要在保证效果的同时降低计算成本。低秩方法被广泛用于降低计算成本——**将一个稠密矩阵近似分解为两个”高瘦“的低秩矩阵**。而且，当原矩阵的奇异值差异较大或快速衰减时，低秩分解的方法会更加有效。作者发现，DCN-M中学到的参数矩阵是低秩的（所以比较适合做矩阵分解）。下图展示了DCN-M中学到的参数矩阵的奇异值衰减趋势，比初始化的矩阵衰减更快：\n",
    "\n",
    "![奇异值衰减趋势](../imgs/singular_value.jpg)\n",
    "\n",
    "因此，作者将参数矩阵$W_l \\in R^{d*d}$分解为两个低秩矩阵$U_l,V_l \\in R^{d*r}$\n",
    "\n",
    "公式有两种解释引发了两种改进：\n",
    "\n",
    "#### （1）在子空间中学习特征交叉\n",
    "\n",
    "改进1：激发了作者使用Mixture-of-Experts (MoE)的思想，在多个子空间中学习特征交互，然后再进行融合。MOE方法包含两部分：专家网络（即上个公式中使用低秩矩阵分解的cross网络）和门控单元（一个关于输入的函数），通过门控单元来聚合个专家网络的输出结果（综合多个专家的意见，但有可能不采纳某些专家的建议）：\n",
    "\n",
    "![moe](../imgs/moe.jpg)\n",
    "\n",
    "#### （2）将输入特征$x$映射到低维空间$R^r$中，然后再映射回到$R^d$\n",
    "\n",
    "改进2：激发了作者利用映射空间的低秩性。在映射回原有空间之前，施加了非线性变换来提炼特征\n",
    "\n",
    "此公式的代码实现：（低秩空间中的非线性函数目前采用tanh)\n",
    "\n",
    "```python\n",
    "  # E(x_l)\n",
    "  # project the input x_l to $\\mathbb{R}^{r}$\n",
    "  v_x = torch.matmul(self.V_list[i][expert_id].T, x_l)  # (bs, low_rank, 1)\n",
    "\n",
    "  # nonlinear activation in low rank space\n",
    "  v_x = torch.tanh(v_x)\n",
    "  v_x = torch.matmul(self.C_list[i][expert_id], v_x)\n",
    "  v_x = torch.tanh(v_x)\n",
    "\n",
    "  # project back to $\\mathbb{R}^{d}$\n",
    "  uv_x = torch.matmul(self.U_list[i][expert_id], v_x)  # (bs, in_features, 1)\n",
    "\n",
    "  dot_ = uv_x + self.bias[i]\n",
    "  dot_ = x_0 * dot_  # Hadamard-product\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9 xdeepFM\n",
    "\n",
    "xDeepFM模型从名字上听好像是deepFM模型的升级，但其实更应该拿来和DCN模型做对比。DCN模型引入了高阶特征交叉，**但是特征的交叉本质上是在bit-wise的**。而**xDeepFM模型认为特征向量$i$和特征向量$j$的交叉过程中，$i$本身的元素交叉没有意义，提取$i$和$j$的向量交叉才是更有效捕捉特征的方式，也就是vector-wise的交叉**，整个模型的框架如下图所示，最核心的模块在于特征交叉的CIN模块。\n",
    "\n",
    "![xdeepfm结构](https://pic2.zhimg.com/80/v2-b0933b44ea2d81d0e50dac3d14852a99_720w.jpg)\n",
    "\n",
    "首先我们来看下整个CIN的整体框架图，如下图所示，假设特征field个数是$m$，每个field的隐层维度emb_size为$D$，那么原始embedding层$x_0$的大小为$m*D$，而cross network有$H_k$层，提取的是特征的交叉。每一层网络在做什么事情呢？就是和第一层$x_0$做**特征交叉得到新的特征向量**后，然后这$H_k$层cross net得到的特征向量`concat`到一起，作为MLP的输入。那么，这里面，每一层的特征$x_k$到底是如何输入层$x_0$发生交互的？\n",
    "\n",
    "![CIN模块结构](https://pic3.zhimg.com/80/v2-5631cee602a80d4042c871abffadea5e_720w.jpg)\n",
    "\n",
    "以cross net的第$k$层和原始输入$x_0$为例，我们看下如何提取得到新的特征，下图是其特征交叉的过程。其中$x_k$的维度为$H_k*D$，表示的是第$k$层有$H_k$个vector，而原始输入$x_0$的维度为$m*D$，表示输入层有$m$个$D$维的vector。\n",
    "\n",
    "![CIN模块中特征交叉过程](https://pic3.zhimg.com/80/v2-4722cd10154302bc95c9a5bb021fa6d2_720w.jpg)\n",
    "\n",
    "![公式](https://pic2.zhimg.com/80/v2-8d14066673a531c347975c572828a1b1_720w.png)\n",
    "\n",
    "这里$W^{k,h}$表示的是第$k$层的第$h$个vector的权重，是模型需要学习的参数。整个公式的理解是整个xdeepFM理解的关键，我们具体看下发生了什么\n",
    "\n",
    "（1） 首先，从前一层的输入$X_{k-1}$(一共有$H_{k-1}$个vector)，取出任意一个vector；从原始输入$x_0$(一共有$m$个vector),取出任意一个vector，两者两两做哈达码积(对应元素相乘)，可以得到$H_{k-1}*m$个vector\n",
    "\n",
    "（2） 这$H_{k-1}*m$个交叉得到的vector，每个vector维度都是$D$，我们通过一个$W$矩阵做乘积进行加权求和，相当于是个带权重的pooling, 最终得到加权求和后的vector $X_h^k$，表示的是第$k$层第$h$个vector。这里的$W$矩阵就是模型要学习的\n",
    "\n",
    "（3） 为什么说是压缩，压缩体现在哪里？还是用图说话，这里我们看下原始论文给出的图示，有助于整个过程的理解。\n",
    "\n",
    "![CIN模块具体结构](https://pic3.zhimg.com/80/v2-1e356d090454af1ab555cb27a49fe936_720w.jpg)\n",
    "\n",
    "在上图的左图中，我们把$D$看成是原始二维平面的宽度，我们沿着$D$的方向挨个进行计算。先看$x_k$向量中$D$的第一维，有$H_k$个数；$x_0$向量中$D$的第一维，有$m$个数，让$H_k$和$m$两两计算，就可以得到$H_k*m$的一个平面。一直沿着$D$方向，2，3，4,…D，我们就可以得到一个$H_k*m*D$的三维矩阵，暂且叫做$z_{k+1}$，注意这个过程只是简单的矩阵计算，没有参数需要学习。\n",
    "\n",
    "在右边的图中，我们开始提取前面$z_{k+1}$的信息，还是以$D$方向的第一维为例，一个$m*H_k$的平面，乘以一个大小一样的$m*H_k$矩阵$W$，然后加权求和，就可以得到这个平面最后压缩的一个实数。整个平面被“压缩“成为了一个一维的数。一直沿着D方向求解每个平面压缩后的数，就可以得到一个$D$维的向量。\n",
    "\n",
    "这就是整个“压缩”的取名原因。整个过程非常类似CNN的filter卷积思想，$W$就是卷积核，得到的每个特征映射的值就是feature map。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
