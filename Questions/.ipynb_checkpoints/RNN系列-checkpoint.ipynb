{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考文献\n",
    "\n",
    "https://www.jiqizhixin.com/articles/2018-12-14-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目录\n",
    "\n",
    "- [RNN](#RNN)\n",
    "- [EncoderDecoder即Seq2Seq](#EncoderDecoder即Seq2Seq)\n",
    "- [Attention](#Attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![121](../imgs/121.png)\n",
    "最基本的单层网络，输入是x，经过变换Wx+b和激活函数f得到输出y。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 to n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以处理的问题有：\n",
    "\n",
    "- 从图像生成文字（image caption），此时输入的X就是图像的特征，而输出的y序列就是一段句子，就像看图说话等\n",
    "- 从类别生成语音或音乐等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 圆圈或方块表示的是向量。\n",
    "- 一个箭头就表示对该向量做一次变换。如上图中h0和x分别有一个箭头连接，就表示对h0和x各做了一次变换。\n",
    "\n",
    "![](../imgs/rnn12n.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n to n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 计算视频中每一帧的分类标签。因为要对每一帧进行计算，因此输入和输出序列等长。\n",
    "- 输入为字符，输出为下一个字符的概率。这就是著名的Char RNN（详细介绍请参考：The Unreasonable Effectiveness of Recurrent Neural Networks，Char RNN可以用来生成文章，诗歌，甚至是代码，非常有意思）。\n",
    "\n",
    "输入输出都是等长序列，经典RNN结构：\n",
    "\n",
    "![](../imgs/rnn4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 处理序列分类问题，输入一段文字判别所属类别。情感分析、文档分类等。\n",
    "\n",
    "要处理的问题输入是一个序列，输出是一个单独的值而不是序列，在最后一个h上进行输出变换：\n",
    "\n",
    "![](../imgs/rnnn21.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EncoderDecoder即Seq2Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n to m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder-Decoder结构不限制输入和输出的序列长度.\n",
    "\n",
    "- 机器翻译：Encoder-Decoder的最经典应用，事实上这结构就是在机器翻译领域最先提出的。\n",
    "- 文本摘要：输入是一段文本序列，输出是这段文本序列的摘要序列。\n",
    "- 阅读理解：将输入的文章和问题分别编码，再对其进行解码得到问题的答案。\n",
    "- 语音识别：输入是语音信号序列，输出是文字序列。\n",
    "\n",
    "\n",
    "### Encoder-Decoder 框架\n",
    "Encoder-Decoder 不是一个具体的模型，是一种框架。\n",
    "\n",
    "- Encoder：将 input序列 →转成→ **固定长度的向量**\n",
    "- Decoder：将 固定长度的向量 →转成→ output序列\n",
    "- Encoder 与 Decoder 可以彼此独立使用，实际上经常一起使用\n",
    "\n",
    "因为最早出现的机器翻译领域，最早广泛使用的转码模型是RNN。其实模型可以是 CNN /RNN /BiRNN /LSTM /GRU /…\n",
    "\n",
    "### Encoder-Decoder 缺点\n",
    "\n",
    "- 最大的局限性：编码和解码之间的**唯一联系是固定长度的语义向量c**\n",
    "- 编码要把**整个序列的信息压缩进一个固定长度的语义向量c**\n",
    "- 语义向量**c无法完全表达整个序列的信息**\n",
    "- 先输入的内容携带的信息，会**被后输入的信息稀释掉**，或者被覆盖掉\n",
    "- 输入序列越长，这样的现象越严重，这样使得在**Decoder解码时一开始就没有获得足够的输入序列信息**，解码效果会打折扣"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于输入与输出不等长，所以**Encoder-Decoder结构先将输入数据编码成一个上下文语义向量c：**\n",
    "\n",
    "![](../imgs/rnnn2m.png)\n",
    "\n",
    "如上图所示，**语义向量C**有多种表达方式。得到C后，用另一个RNN网络(Decoder)对C进行解码。在Decoder中，`h0=c`:\n",
    "\n",
    "![](../imgs/rnnn2m2.png)\n",
    "\n",
    "或者\n",
    "\n",
    "![](../imgs/rnnn2m3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了弥补基础的 Encoder-Decoder 的局限性，提出了attention机制。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention 的优点：\n",
    "\n",
    "- 在机器翻译时，让生词不只是关注全局的语义向量c，**增加了“注意力范围”**。表示**接下来输出的词要重点关注输入序列中的哪些部分**。根据关注的区域来产生下一个输出。\n",
    "- 不要求编码器将所有信息全输入在一个固定长度的向量中。\n",
    "- 将输入编码成一个向量的序列，解码时，每一步选择性的从序列中挑一个子集进行处理。【加权挑选】\n",
    "- 在每一个输出时，**能够充分利用输入携带的信息**，**每个语义向量Ci不一样**，注意力焦点不一样。\n",
    "\n",
    "## Attention 的缺点：\n",
    "\n",
    "- 需要为每个输入输出组合分别计算attention即**M\\*N个参数**。50个单词的输出输出序列需要计算2500个attention。\n",
    "- attention在决定专注于某个方面之前需要遍历一遍记忆（Decoder中$h'$）再决定下一个输出是以什么。\n",
    "- Attention的另一种替代方法是强化学习，来预测关注点的大概位置。但强化学习不能用反向传播算法端到端的训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention机制通过**在每个时间输入不同的c**来解决Encoder-Decoder的问题，下图是带有Attention机制的Decoder(encoder没画出来)：\n",
    "\n",
    "![](../imgs/rnnatt1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**每一个c会自动去选取与当前所要输出的y最合适的上下文信息。**具体来说，我们用**$a_{ij}$衡量Encoder中第j阶段的$h_j$和Decoder时第i阶段的相关性**，最终**Decoder**中第i阶段的输入的上下文信息 $c_i$就来自于所有 $h_j$ 对 $a_{ij}$ 的加权和。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以机器翻译为例（将中文翻译成英文）：\n",
    "\n",
    "![ec例子](../imgs/rnned1.jpg)\n",
    "\n",
    "其中，输入序列是中文\"我爱中国\"，绿色方框$h_1,h_2,h_3,h_4$在Encoder中，可以分别看做是四个中文字代表的信息。\n",
    "\n",
    "翻译成英语时，Decoder第一个输入$c_1$应该和“我”字最相关，因此对应的$a_{11}$就较大，$a_{12},a_{13},a_{14}$就应该比较小。$c_2$应该和“爱”最相关，因此$a_{12}$就比较大；最后$c_3$和$h_3,h_4$最相关，因此$a_{13},a_{14}$的值就比较大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$a_{ij}$是从模型中学习来的**，$a_{ij}$和Decoder中$h'_{i-1},i=1,2,..,M$、Encoder中$h_j,j=1,2,...,N$相关，如下图展示$a_{1j},a_{2j},a_{3j}$：\n",
    "\n",
    "![](../imgs/rnned2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "参考文献：\n",
    "\n",
    "- https://arxiv.org/pdf/1706.03762.pdf\n",
    "- https://arxiv.org/pdf/1502.03044v1.pdf\n",
    "- https://arxiv.org/pdf/1705.03122.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
